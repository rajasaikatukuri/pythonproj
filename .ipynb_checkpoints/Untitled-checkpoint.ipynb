{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "b680ec05-db51-4f20-8ecf-e37af534b87e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (2.2.3)\n",
      "Requirement already satisfied: seaborn in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (0.13.2)\n",
      "Requirement already satisfied: matplotlib in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (3.10.0)\n",
      "Requirement already satisfied: scikit-learn in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (1.6.0)\n",
      "Requirement already satisfied: mlflow in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (2.19.0)\n",
      "Requirement already satisfied: xgboost in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (2.1.3)\n",
      "Requirement already satisfied: numpy>=1.26.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from pandas) (2.2.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from pandas) (2024.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from pandas) (2024.2)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from matplotlib) (1.3.1)\n",
      "Requirement already satisfied: cycler>=0.10 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from matplotlib) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from matplotlib) (4.55.3)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from matplotlib) (1.4.7)\n",
      "Requirement already satisfied: packaging>=20.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from matplotlib) (24.2)\n",
      "Requirement already satisfied: pillow>=8 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from matplotlib) (11.0.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from matplotlib) (3.2.0)\n",
      "Requirement already satisfied: scipy>=1.6.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from scikit-learn) (1.14.1)\n",
      "Requirement already satisfied: joblib>=1.2.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from scikit-learn) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from scikit-learn) (3.5.0)\n",
      "Requirement already satisfied: mlflow-skinny==2.19.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from mlflow) (2.19.0)\n",
      "Requirement already satisfied: Flask<4 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from mlflow) (3.1.0)\n",
      "Requirement already satisfied: Jinja2<4,>=2.11 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from mlflow) (3.1.4)\n",
      "Requirement already satisfied: alembic!=1.10.0,<2 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from mlflow) (1.14.0)\n",
      "Requirement already satisfied: docker<8,>=4.0.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from mlflow) (7.1.0)\n",
      "Requirement already satisfied: graphene<4 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from mlflow) (3.4.3)\n",
      "Requirement already satisfied: gunicorn<24 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from mlflow) (23.0.0)\n",
      "Requirement already satisfied: markdown<4,>=3.3 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from mlflow) (3.7)\n",
      "Requirement already satisfied: pyarrow<19,>=4.0.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from mlflow) (18.1.0)\n",
      "Requirement already satisfied: sqlalchemy<3,>=1.4.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from mlflow) (2.0.36)\n",
      "Requirement already satisfied: cachetools<6,>=5.0.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from mlflow-skinny==2.19.0->mlflow) (5.5.0)\n",
      "Requirement already satisfied: click<9,>=7.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from mlflow-skinny==2.19.0->mlflow) (8.1.7)\n",
      "Requirement already satisfied: cloudpickle<4 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from mlflow-skinny==2.19.0->mlflow) (3.1.0)\n",
      "Requirement already satisfied: databricks-sdk<1,>=0.20.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from mlflow-skinny==2.19.0->mlflow) (0.39.0)\n",
      "Requirement already satisfied: gitpython<4,>=3.1.9 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from mlflow-skinny==2.19.0->mlflow) (3.1.43)\n",
      "Requirement already satisfied: importlib_metadata!=4.7.0,<9,>=3.7.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from mlflow-skinny==2.19.0->mlflow) (8.5.0)\n",
      "Requirement already satisfied: opentelemetry-api<3,>=1.9.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from mlflow-skinny==2.19.0->mlflow) (1.29.0)\n",
      "Requirement already satisfied: opentelemetry-sdk<3,>=1.9.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from mlflow-skinny==2.19.0->mlflow) (1.29.0)\n",
      "Requirement already satisfied: protobuf<6,>=3.12.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from mlflow-skinny==2.19.0->mlflow) (5.29.2)\n",
      "Requirement already satisfied: pyyaml<7,>=5.1 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from mlflow-skinny==2.19.0->mlflow) (6.0.2)\n",
      "Requirement already satisfied: requests<3,>=2.17.3 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from mlflow-skinny==2.19.0->mlflow) (2.32.3)\n",
      "Requirement already satisfied: sqlparse<1,>=0.4.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from mlflow-skinny==2.19.0->mlflow) (0.5.3)\n",
      "Requirement already satisfied: Mako in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from alembic!=1.10.0,<2->mlflow) (1.3.8)\n",
      "Requirement already satisfied: typing-extensions>=4 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from alembic!=1.10.0,<2->mlflow) (4.12.2)\n",
      "Requirement already satisfied: urllib3>=1.26.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from docker<8,>=4.0.0->mlflow) (2.2.3)\n",
      "Requirement already satisfied: Werkzeug>=3.1 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from Flask<4->mlflow) (3.1.3)\n",
      "Requirement already satisfied: itsdangerous>=2.2 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from Flask<4->mlflow) (2.2.0)\n",
      "Requirement already satisfied: blinker>=1.9 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from Flask<4->mlflow) (1.9.0)\n",
      "Requirement already satisfied: graphql-core<3.3,>=3.1 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from graphene<4->mlflow) (3.2.5)\n",
      "Requirement already satisfied: graphql-relay<3.3,>=3.1 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from graphene<4->mlflow) (3.2.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from Jinja2<4,>=2.11->mlflow) (3.0.2)\n",
      "Requirement already satisfied: six>=1.5 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
      "Requirement already satisfied: google-auth~=2.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from databricks-sdk<1,>=0.20.0->mlflow-skinny==2.19.0->mlflow) (2.37.0)\n",
      "Requirement already satisfied: gitdb<5,>=4.0.1 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from gitpython<4,>=3.1.9->mlflow-skinny==2.19.0->mlflow) (4.0.11)\n",
      "Requirement already satisfied: zipp>=3.20 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from importlib_metadata!=4.7.0,<9,>=3.7.0->mlflow-skinny==2.19.0->mlflow) (3.21.0)\n",
      "Requirement already satisfied: deprecated>=1.2.6 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from opentelemetry-api<3,>=1.9.0->mlflow-skinny==2.19.0->mlflow) (1.2.15)\n",
      "Requirement already satisfied: opentelemetry-semantic-conventions==0.50b0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from opentelemetry-sdk<3,>=1.9.0->mlflow-skinny==2.19.0->mlflow) (0.50b0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from requests<3,>=2.17.3->mlflow-skinny==2.19.0->mlflow) (3.4.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from requests<3,>=2.17.3->mlflow-skinny==2.19.0->mlflow) (3.10)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from requests<3,>=2.17.3->mlflow-skinny==2.19.0->mlflow) (2024.12.14)\n",
      "Requirement already satisfied: wrapt<2,>=1.10 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from deprecated>=1.2.6->opentelemetry-api<3,>=1.9.0->mlflow-skinny==2.19.0->mlflow) (1.17.0)\n",
      "Requirement already satisfied: smmap<6,>=3.0.1 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from gitdb<5,>=4.0.1->gitpython<4,>=3.1.9->mlflow-skinny==2.19.0->mlflow) (5.0.1)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from google-auth~=2.0->databricks-sdk<1,>=0.20.0->mlflow-skinny==2.19.0->mlflow) (0.4.1)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from google-auth~=2.0->databricks-sdk<1,>=0.20.0->mlflow-skinny==2.19.0->mlflow) (4.9)\n",
      "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from pyasn1-modules>=0.2.1->google-auth~=2.0->databricks-sdk<1,>=0.20.0->mlflow-skinny==2.19.0->mlflow) (0.6.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install pandas seaborn matplotlib scikit-learn mlflow xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "cc523b0d-66e8-41b4-82f5-357cb17c5a64",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import sqlite3\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import cross_val_score, train_test_split, GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler, FunctionTransformer\n",
    "from sklearn.feature_selection import VarianceThreshold, SelectKBest, f_classif\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.linear_model import LogisticRegression, RidgeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix, f1_score\n",
    "import numpy as np\n",
    "import mlflow\n",
    "import mlflow.sklearn\n",
    "import joblib\n",
    "from sklearn.base import BaseEstimator, ClassifierMixin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "fda8e787-be0f-41da-baf5-c6705ddee6a6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>diagnosis</th>\n",
       "      <th>radius_mean</th>\n",
       "      <th>texture_mean</th>\n",
       "      <th>perimeter_mean</th>\n",
       "      <th>area_mean</th>\n",
       "      <th>smoothness_mean</th>\n",
       "      <th>compactness_mean</th>\n",
       "      <th>concavity_mean</th>\n",
       "      <th>concave points_mean</th>\n",
       "      <th>...</th>\n",
       "      <th>radius_worst</th>\n",
       "      <th>texture_worst</th>\n",
       "      <th>perimeter_worst</th>\n",
       "      <th>area_worst</th>\n",
       "      <th>smoothness_worst</th>\n",
       "      <th>compactness_worst</th>\n",
       "      <th>concavity_worst</th>\n",
       "      <th>concave points_worst</th>\n",
       "      <th>symmetry_worst</th>\n",
       "      <th>fractal_dimension_worst</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>842302</td>\n",
       "      <td>M</td>\n",
       "      <td>17.99</td>\n",
       "      <td>10.38</td>\n",
       "      <td>122.80</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>0.11840</td>\n",
       "      <td>0.27760</td>\n",
       "      <td>0.30010</td>\n",
       "      <td>0.14710</td>\n",
       "      <td>...</td>\n",
       "      <td>25.380</td>\n",
       "      <td>17.33</td>\n",
       "      <td>184.60</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>0.16220</td>\n",
       "      <td>0.66560</td>\n",
       "      <td>0.7119</td>\n",
       "      <td>0.2654</td>\n",
       "      <td>0.4601</td>\n",
       "      <td>0.11890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>842517</td>\n",
       "      <td>M</td>\n",
       "      <td>20.57</td>\n",
       "      <td>17.77</td>\n",
       "      <td>132.90</td>\n",
       "      <td>1326.0</td>\n",
       "      <td>0.08474</td>\n",
       "      <td>0.07864</td>\n",
       "      <td>0.08690</td>\n",
       "      <td>0.07017</td>\n",
       "      <td>...</td>\n",
       "      <td>24.990</td>\n",
       "      <td>23.41</td>\n",
       "      <td>158.80</td>\n",
       "      <td>1956.0</td>\n",
       "      <td>0.12380</td>\n",
       "      <td>0.18660</td>\n",
       "      <td>0.2416</td>\n",
       "      <td>0.1860</td>\n",
       "      <td>0.2750</td>\n",
       "      <td>0.08902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>84300903</td>\n",
       "      <td>M</td>\n",
       "      <td>19.69</td>\n",
       "      <td>21.25</td>\n",
       "      <td>130.00</td>\n",
       "      <td>1203.0</td>\n",
       "      <td>0.10960</td>\n",
       "      <td>0.15990</td>\n",
       "      <td>0.19740</td>\n",
       "      <td>0.12790</td>\n",
       "      <td>...</td>\n",
       "      <td>23.570</td>\n",
       "      <td>25.53</td>\n",
       "      <td>152.50</td>\n",
       "      <td>1709.0</td>\n",
       "      <td>0.14440</td>\n",
       "      <td>0.42450</td>\n",
       "      <td>0.4504</td>\n",
       "      <td>0.2430</td>\n",
       "      <td>0.3613</td>\n",
       "      <td>0.08758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>84348301</td>\n",
       "      <td>M</td>\n",
       "      <td>11.42</td>\n",
       "      <td>20.38</td>\n",
       "      <td>77.58</td>\n",
       "      <td>386.1</td>\n",
       "      <td>0.14250</td>\n",
       "      <td>0.28390</td>\n",
       "      <td>0.24140</td>\n",
       "      <td>0.10520</td>\n",
       "      <td>...</td>\n",
       "      <td>14.910</td>\n",
       "      <td>26.50</td>\n",
       "      <td>98.87</td>\n",
       "      <td>567.7</td>\n",
       "      <td>0.20980</td>\n",
       "      <td>0.86630</td>\n",
       "      <td>0.6869</td>\n",
       "      <td>0.2575</td>\n",
       "      <td>0.6638</td>\n",
       "      <td>0.17300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>84358402</td>\n",
       "      <td>M</td>\n",
       "      <td>20.29</td>\n",
       "      <td>14.34</td>\n",
       "      <td>135.10</td>\n",
       "      <td>1297.0</td>\n",
       "      <td>0.10030</td>\n",
       "      <td>0.13280</td>\n",
       "      <td>0.19800</td>\n",
       "      <td>0.10430</td>\n",
       "      <td>...</td>\n",
       "      <td>22.540</td>\n",
       "      <td>16.67</td>\n",
       "      <td>152.20</td>\n",
       "      <td>1575.0</td>\n",
       "      <td>0.13740</td>\n",
       "      <td>0.20500</td>\n",
       "      <td>0.4000</td>\n",
       "      <td>0.1625</td>\n",
       "      <td>0.2364</td>\n",
       "      <td>0.07678</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>564</th>\n",
       "      <td>926424</td>\n",
       "      <td>M</td>\n",
       "      <td>21.56</td>\n",
       "      <td>22.39</td>\n",
       "      <td>142.00</td>\n",
       "      <td>1479.0</td>\n",
       "      <td>0.11100</td>\n",
       "      <td>0.11590</td>\n",
       "      <td>0.24390</td>\n",
       "      <td>0.13890</td>\n",
       "      <td>...</td>\n",
       "      <td>25.450</td>\n",
       "      <td>26.40</td>\n",
       "      <td>166.10</td>\n",
       "      <td>2027.0</td>\n",
       "      <td>0.14100</td>\n",
       "      <td>0.21130</td>\n",
       "      <td>0.4107</td>\n",
       "      <td>0.2216</td>\n",
       "      <td>0.2060</td>\n",
       "      <td>0.07115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>565</th>\n",
       "      <td>926682</td>\n",
       "      <td>M</td>\n",
       "      <td>20.13</td>\n",
       "      <td>28.25</td>\n",
       "      <td>131.20</td>\n",
       "      <td>1261.0</td>\n",
       "      <td>0.09780</td>\n",
       "      <td>0.10340</td>\n",
       "      <td>0.14400</td>\n",
       "      <td>0.09791</td>\n",
       "      <td>...</td>\n",
       "      <td>23.690</td>\n",
       "      <td>38.25</td>\n",
       "      <td>155.00</td>\n",
       "      <td>1731.0</td>\n",
       "      <td>0.11660</td>\n",
       "      <td>0.19220</td>\n",
       "      <td>0.3215</td>\n",
       "      <td>0.1628</td>\n",
       "      <td>0.2572</td>\n",
       "      <td>0.06637</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>566</th>\n",
       "      <td>926954</td>\n",
       "      <td>M</td>\n",
       "      <td>16.60</td>\n",
       "      <td>28.08</td>\n",
       "      <td>108.30</td>\n",
       "      <td>858.1</td>\n",
       "      <td>0.08455</td>\n",
       "      <td>0.10230</td>\n",
       "      <td>0.09251</td>\n",
       "      <td>0.05302</td>\n",
       "      <td>...</td>\n",
       "      <td>18.980</td>\n",
       "      <td>34.12</td>\n",
       "      <td>126.70</td>\n",
       "      <td>1124.0</td>\n",
       "      <td>0.11390</td>\n",
       "      <td>0.30940</td>\n",
       "      <td>0.3403</td>\n",
       "      <td>0.1418</td>\n",
       "      <td>0.2218</td>\n",
       "      <td>0.07820</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>567</th>\n",
       "      <td>927241</td>\n",
       "      <td>M</td>\n",
       "      <td>20.60</td>\n",
       "      <td>29.33</td>\n",
       "      <td>140.10</td>\n",
       "      <td>1265.0</td>\n",
       "      <td>0.11780</td>\n",
       "      <td>0.27700</td>\n",
       "      <td>0.35140</td>\n",
       "      <td>0.15200</td>\n",
       "      <td>...</td>\n",
       "      <td>25.740</td>\n",
       "      <td>39.42</td>\n",
       "      <td>184.60</td>\n",
       "      <td>1821.0</td>\n",
       "      <td>0.16500</td>\n",
       "      <td>0.86810</td>\n",
       "      <td>0.9387</td>\n",
       "      <td>0.2650</td>\n",
       "      <td>0.4087</td>\n",
       "      <td>0.12400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>568</th>\n",
       "      <td>92751</td>\n",
       "      <td>B</td>\n",
       "      <td>7.76</td>\n",
       "      <td>24.54</td>\n",
       "      <td>47.92</td>\n",
       "      <td>181.0</td>\n",
       "      <td>0.05263</td>\n",
       "      <td>0.04362</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>...</td>\n",
       "      <td>9.456</td>\n",
       "      <td>30.37</td>\n",
       "      <td>59.16</td>\n",
       "      <td>268.6</td>\n",
       "      <td>0.08996</td>\n",
       "      <td>0.06444</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.2871</td>\n",
       "      <td>0.07039</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>569 rows × 32 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           id diagnosis  radius_mean  texture_mean  perimeter_mean  area_mean  \\\n",
       "0      842302         M        17.99         10.38          122.80     1001.0   \n",
       "1      842517         M        20.57         17.77          132.90     1326.0   \n",
       "2    84300903         M        19.69         21.25          130.00     1203.0   \n",
       "3    84348301         M        11.42         20.38           77.58      386.1   \n",
       "4    84358402         M        20.29         14.34          135.10     1297.0   \n",
       "..        ...       ...          ...           ...             ...        ...   \n",
       "564    926424         M        21.56         22.39          142.00     1479.0   \n",
       "565    926682         M        20.13         28.25          131.20     1261.0   \n",
       "566    926954         M        16.60         28.08          108.30      858.1   \n",
       "567    927241         M        20.60         29.33          140.10     1265.0   \n",
       "568     92751         B         7.76         24.54           47.92      181.0   \n",
       "\n",
       "     smoothness_mean  compactness_mean  concavity_mean  concave points_mean  \\\n",
       "0            0.11840           0.27760         0.30010              0.14710   \n",
       "1            0.08474           0.07864         0.08690              0.07017   \n",
       "2            0.10960           0.15990         0.19740              0.12790   \n",
       "3            0.14250           0.28390         0.24140              0.10520   \n",
       "4            0.10030           0.13280         0.19800              0.10430   \n",
       "..               ...               ...             ...                  ...   \n",
       "564          0.11100           0.11590         0.24390              0.13890   \n",
       "565          0.09780           0.10340         0.14400              0.09791   \n",
       "566          0.08455           0.10230         0.09251              0.05302   \n",
       "567          0.11780           0.27700         0.35140              0.15200   \n",
       "568          0.05263           0.04362         0.00000              0.00000   \n",
       "\n",
       "     ...  radius_worst  texture_worst  perimeter_worst  area_worst  \\\n",
       "0    ...        25.380          17.33           184.60      2019.0   \n",
       "1    ...        24.990          23.41           158.80      1956.0   \n",
       "2    ...        23.570          25.53           152.50      1709.0   \n",
       "3    ...        14.910          26.50            98.87       567.7   \n",
       "4    ...        22.540          16.67           152.20      1575.0   \n",
       "..   ...           ...            ...              ...         ...   \n",
       "564  ...        25.450          26.40           166.10      2027.0   \n",
       "565  ...        23.690          38.25           155.00      1731.0   \n",
       "566  ...        18.980          34.12           126.70      1124.0   \n",
       "567  ...        25.740          39.42           184.60      1821.0   \n",
       "568  ...         9.456          30.37            59.16       268.6   \n",
       "\n",
       "     smoothness_worst  compactness_worst  concavity_worst  \\\n",
       "0             0.16220            0.66560           0.7119   \n",
       "1             0.12380            0.18660           0.2416   \n",
       "2             0.14440            0.42450           0.4504   \n",
       "3             0.20980            0.86630           0.6869   \n",
       "4             0.13740            0.20500           0.4000   \n",
       "..                ...                ...              ...   \n",
       "564           0.14100            0.21130           0.4107   \n",
       "565           0.11660            0.19220           0.3215   \n",
       "566           0.11390            0.30940           0.3403   \n",
       "567           0.16500            0.86810           0.9387   \n",
       "568           0.08996            0.06444           0.0000   \n",
       "\n",
       "     concave points_worst  symmetry_worst  fractal_dimension_worst  \n",
       "0                  0.2654          0.4601                  0.11890  \n",
       "1                  0.1860          0.2750                  0.08902  \n",
       "2                  0.2430          0.3613                  0.08758  \n",
       "3                  0.2575          0.6638                  0.17300  \n",
       "4                  0.1625          0.2364                  0.07678  \n",
       "..                    ...             ...                      ...  \n",
       "564                0.2216          0.2060                  0.07115  \n",
       "565                0.1628          0.2572                  0.06637  \n",
       "566                0.1418          0.2218                  0.07820  \n",
       "567                0.2650          0.4087                  0.12400  \n",
       "568                0.0000          0.2871                  0.07039  \n",
       "\n",
       "[569 rows x 32 columns]"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_path = '/Users/rajasaikatukuri/Downloads/pythonproject/breast-cancer.csv'\n",
    "data = pd.read_csv(file_path)\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "bd00311b-4381-473e-8e0c-b4227cb21a90",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "17070"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Data Normalization Process\n",
    "# Establish SQLite connection\n",
    "conn = sqlite3.connect(\"breast_cancer_normalized.db\")\n",
    "cursor = conn.cursor()\n",
    "\n",
    "# Define the SQL schema for normalization\n",
    "# Table 1: Patients\n",
    "cursor.execute(\"\"\"\n",
    "CREATE TABLE IF NOT EXISTS Patients (\n",
    "    PatientID INTEGER PRIMARY KEY,\n",
    "    Diagnosis TEXT\n",
    ");\n",
    "\"\"\")\n",
    "\n",
    "# Table 2: Measurements\n",
    "cursor.execute(\"\"\"\n",
    "CREATE TABLE IF NOT EXISTS Measurements (\n",
    "    PatientID INTEGER,\n",
    "    MeasurementType TEXT,\n",
    "    Value REAL,\n",
    "    FOREIGN KEY (PatientID) REFERENCES Patients(PatientID)\n",
    ");\n",
    "\"\"\")\n",
    "\n",
    "# Insert data into Patients table\n",
    "patients_data = data[['id', 'diagnosis']].rename(columns={'id': 'PatientID', 'diagnosis': 'Diagnosis'})\n",
    "patients_data.to_sql('Patients', conn, if_exists='replace', index=False)\n",
    "\n",
    "# Transform measurements into a long format and insert into Measurements table\n",
    "measurements = data.drop(columns=['id', 'diagnosis'])\n",
    "measurements['PatientID'] = data['id']\n",
    "measurements_long = measurements.melt(\n",
    "    id_vars=['PatientID'],\n",
    "    var_name=\"MeasurementType\",\n",
    "    value_name=\"Value\"\n",
    ")\n",
    "measurements_long.to_sql('Measurements', conn, if_exists='replace', index=False)\n",
    "\n",
    "# Verify data insertion\n",
    "print(\"Patients Table:\")\n",
    "print(pd.read_sql_query(\"SELECT * FROM Patients LIMIT 5;\", conn))\n",
    "print(\"\\nMeasurements Table:\")\n",
    "print(pd.read_sql_query(\"SELECT * FROM Measurements LIMIT 5;\", conn))\n",
    "\n",
    "# Verify all columns are normalized\n",
    "print(\"\\nDistinct Measurement Types:\")\n",
    "print(pd.read_sql_query(\"SELECT DISTINCT MeasurementType FROM Measurements;\", conn))\n",
    "\n",
    "print(\"\\nTotal Rows in Measurements Table:\")\n",
    "print(pd.read_sql_query(\"SELECT COUNT(*) FROM Measurements;\", conn))\n",
    "\n",
    "#Data Distribution per Column\n",
    "distribution_query = \"\"\"\n",
    "SELECT MeasurementType, COUNT(*) AS Count\n",
    "FROM Measurements\n",
    "GROUP BY MeasurementType\n",
    "ORDER BY MeasurementType;\n",
    "\"\"\"\n",
    "column_distribution = pd.read_sql_query(distribution_query, conn)\n",
    "print(\"\\nData Distribution per Column:\")\n",
    "print(column_distribution)\n",
    "\n",
    "# Data Exploration\n",
    "# Fetch data for analysis\n",
    "query = \"\"\"\n",
    "SELECT Patients.PatientID, Patients.Diagnosis, Measurements.MeasurementType, Measurements.Value\n",
    "FROM Patients\n",
    "JOIN Measurements ON Patients.PatientID = Measurements.PatientID\n",
    "\"\"\"\n",
    "data_normalized = pd.read_sql_query(query, conn)\n",
    "\n",
    "# Pivot the data back for exploration\n",
    "data_pivoted = data_normalized.pivot_table(index='PatientID', columns='MeasurementType', values='Value', aggfunc='mean')\n",
    "data_pivoted['Diagnosis'] = data_normalized.groupby('PatientID')['Diagnosis'].first()\n",
    "\n",
    "# Encode target variable\n",
    "data_pivoted['Diagnosis'] = data_pivoted['Diagnosis'].map({'M': 1, 'B': 0})\n",
    "\n",
    "# Check for missing values\n",
    "missing_values = data_pivoted.isnull().sum()\n",
    "print(\"\\nMissing Values per Column:\")\n",
    "print(missing_values)\n",
    "\n",
    "# Handle missing values (e.g., fill with mean or drop rows with missing values)\n",
    "data_pivoted.fillna(data_pivoted.mean(), inplace=True)\n",
    "print(\"\\nMissing Values after Imputation:\")\n",
    "print(data_pivoted.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "a18a3540-6c1a-47bf-8bda-5dea8e28b7d4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "ce776091-71c9-4c77-8ffb-5fe2882c0f11",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>MeasurementType</th>\n",
       "      <th>area_mean</th>\n",
       "      <th>area_se</th>\n",
       "      <th>area_worst</th>\n",
       "      <th>compactness_mean</th>\n",
       "      <th>compactness_se</th>\n",
       "      <th>compactness_worst</th>\n",
       "      <th>concave points_mean</th>\n",
       "      <th>concave points_se</th>\n",
       "      <th>concave points_worst</th>\n",
       "      <th>concavity_mean</th>\n",
       "      <th>...</th>\n",
       "      <th>symmetry_se</th>\n",
       "      <th>symmetry_worst</th>\n",
       "      <th>texture_mean</th>\n",
       "      <th>texture_se</th>\n",
       "      <th>texture_worst</th>\n",
       "      <th>Diagnosis</th>\n",
       "      <th>Area_Perimeter_Ratio</th>\n",
       "      <th>Concavity_Compactness_Product</th>\n",
       "      <th>Smoothness_Symmetry_Avg</th>\n",
       "      <th>Texture_Area_Ratio</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PatientID</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>8670</th>\n",
       "      <td>748.9</td>\n",
       "      <td>48.31</td>\n",
       "      <td>1156.0</td>\n",
       "      <td>0.12230</td>\n",
       "      <td>0.01484</td>\n",
       "      <td>0.2394</td>\n",
       "      <td>0.08087</td>\n",
       "      <td>0.010930</td>\n",
       "      <td>0.15140</td>\n",
       "      <td>0.14660</td>\n",
       "      <td>...</td>\n",
       "      <td>0.01397</td>\n",
       "      <td>0.2837</td>\n",
       "      <td>19.48</td>\n",
       "      <td>0.7859</td>\n",
       "      <td>26.00</td>\n",
       "      <td>1</td>\n",
       "      <td>7.292113</td>\n",
       "      <td>0.017929</td>\n",
       "      <td>0.151150</td>\n",
       "      <td>0.025977</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8913</th>\n",
       "      <td>515.9</td>\n",
       "      <td>12.68</td>\n",
       "      <td>577.0</td>\n",
       "      <td>0.03729</td>\n",
       "      <td>0.01345</td>\n",
       "      <td>0.1147</td>\n",
       "      <td>0.01171</td>\n",
       "      <td>0.005905</td>\n",
       "      <td>0.05366</td>\n",
       "      <td>0.02260</td>\n",
       "      <td>...</td>\n",
       "      <td>0.01619</td>\n",
       "      <td>0.2309</td>\n",
       "      <td>13.12</td>\n",
       "      <td>0.4690</td>\n",
       "      <td>15.54</td>\n",
       "      <td>0</td>\n",
       "      <td>6.223911</td>\n",
       "      <td>0.000843</td>\n",
       "      <td>0.101625</td>\n",
       "      <td>0.025382</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8915</th>\n",
       "      <td>687.3</td>\n",
       "      <td>24.87</td>\n",
       "      <td>809.8</td>\n",
       "      <td>0.09823</td>\n",
       "      <td>0.02115</td>\n",
       "      <td>0.3030</td>\n",
       "      <td>0.04819</td>\n",
       "      <td>0.011870</td>\n",
       "      <td>0.14890</td>\n",
       "      <td>0.05940</td>\n",
       "      <td>...</td>\n",
       "      <td>0.01522</td>\n",
       "      <td>0.2962</td>\n",
       "      <td>19.10</td>\n",
       "      <td>0.9480</td>\n",
       "      <td>26.19</td>\n",
       "      <td>0</td>\n",
       "      <td>7.011119</td>\n",
       "      <td>0.005835</td>\n",
       "      <td>0.138910</td>\n",
       "      <td>0.027750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9047</th>\n",
       "      <td>507.6</td>\n",
       "      <td>11.36</td>\n",
       "      <td>580.9</td>\n",
       "      <td>0.08836</td>\n",
       "      <td>0.01285</td>\n",
       "      <td>0.1958</td>\n",
       "      <td>0.02390</td>\n",
       "      <td>0.007308</td>\n",
       "      <td>0.08388</td>\n",
       "      <td>0.03296</td>\n",
       "      <td>...</td>\n",
       "      <td>0.01870</td>\n",
       "      <td>0.3297</td>\n",
       "      <td>16.17</td>\n",
       "      <td>0.9050</td>\n",
       "      <td>23.02</td>\n",
       "      <td>0</td>\n",
       "      <td>6.029936</td>\n",
       "      <td>0.002912</td>\n",
       "      <td>0.136145</td>\n",
       "      <td>0.031793</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85715</th>\n",
       "      <td>534.6</td>\n",
       "      <td>24.25</td>\n",
       "      <td>759.4</td>\n",
       "      <td>0.12310</td>\n",
       "      <td>0.02336</td>\n",
       "      <td>0.4166</td>\n",
       "      <td>0.07340</td>\n",
       "      <td>0.012150</td>\n",
       "      <td>0.20880</td>\n",
       "      <td>0.12260</td>\n",
       "      <td>...</td>\n",
       "      <td>0.01743</td>\n",
       "      <td>0.3900</td>\n",
       "      <td>18.66</td>\n",
       "      <td>0.8937</td>\n",
       "      <td>27.95</td>\n",
       "      <td>1</td>\n",
       "      <td>6.146241</td>\n",
       "      <td>0.015092</td>\n",
       "      <td>0.164300</td>\n",
       "      <td>0.034839</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>911157302</th>\n",
       "      <td>1384.0</td>\n",
       "      <td>81.89</td>\n",
       "      <td>2022.0</td>\n",
       "      <td>0.11750</td>\n",
       "      <td>0.02075</td>\n",
       "      <td>0.3101</td>\n",
       "      <td>0.11550</td>\n",
       "      <td>0.014660</td>\n",
       "      <td>0.22800</td>\n",
       "      <td>0.15720</td>\n",
       "      <td>...</td>\n",
       "      <td>0.01029</td>\n",
       "      <td>0.2268</td>\n",
       "      <td>20.52</td>\n",
       "      <td>1.3610</td>\n",
       "      <td>32.07</td>\n",
       "      <td>1</td>\n",
       "      <td>9.949676</td>\n",
       "      <td>0.018471</td>\n",
       "      <td>0.126120</td>\n",
       "      <td>0.014816</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>911296201</th>\n",
       "      <td>930.9</td>\n",
       "      <td>115.20</td>\n",
       "      <td>1648.0</td>\n",
       "      <td>0.11100</td>\n",
       "      <td>0.02219</td>\n",
       "      <td>0.2444</td>\n",
       "      <td>0.06431</td>\n",
       "      <td>0.014580</td>\n",
       "      <td>0.15550</td>\n",
       "      <td>0.10070</td>\n",
       "      <td>...</td>\n",
       "      <td>0.02045</td>\n",
       "      <td>0.3010</td>\n",
       "      <td>27.15</td>\n",
       "      <td>1.1520</td>\n",
       "      <td>34.49</td>\n",
       "      <td>1</td>\n",
       "      <td>8.296791</td>\n",
       "      <td>0.011178</td>\n",
       "      <td>0.139140</td>\n",
       "      <td>0.029134</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>911296202</th>\n",
       "      <td>2501.0</td>\n",
       "      <td>542.20</td>\n",
       "      <td>4254.0</td>\n",
       "      <td>0.19880</td>\n",
       "      <td>0.05374</td>\n",
       "      <td>0.4256</td>\n",
       "      <td>0.16890</td>\n",
       "      <td>0.025980</td>\n",
       "      <td>0.26250</td>\n",
       "      <td>0.36350</td>\n",
       "      <td>...</td>\n",
       "      <td>0.01697</td>\n",
       "      <td>0.2641</td>\n",
       "      <td>26.27</td>\n",
       "      <td>1.3060</td>\n",
       "      <td>31.37</td>\n",
       "      <td>1</td>\n",
       "      <td>13.310271</td>\n",
       "      <td>0.072264</td>\n",
       "      <td>0.157250</td>\n",
       "      <td>0.010500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>911320501</th>\n",
       "      <td>412.7</td>\n",
       "      <td>12.89</td>\n",
       "      <td>495.1</td>\n",
       "      <td>0.05855</td>\n",
       "      <td>0.01701</td>\n",
       "      <td>0.1808</td>\n",
       "      <td>0.01777</td>\n",
       "      <td>0.007497</td>\n",
       "      <td>0.08288</td>\n",
       "      <td>0.03367</td>\n",
       "      <td>...</td>\n",
       "      <td>0.02124</td>\n",
       "      <td>0.3210</td>\n",
       "      <td>18.36</td>\n",
       "      <td>0.7656</td>\n",
       "      <td>24.02</td>\n",
       "      <td>0</td>\n",
       "      <td>5.511485</td>\n",
       "      <td>0.001971</td>\n",
       "      <td>0.118340</td>\n",
       "      <td>0.044380</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>911320502</th>\n",
       "      <td>537.3</td>\n",
       "      <td>16.89</td>\n",
       "      <td>687.6</td>\n",
       "      <td>0.05994</td>\n",
       "      <td>0.01493</td>\n",
       "      <td>0.1965</td>\n",
       "      <td>0.02870</td>\n",
       "      <td>0.008463</td>\n",
       "      <td>0.10450</td>\n",
       "      <td>0.04859</td>\n",
       "      <td>...</td>\n",
       "      <td>0.01093</td>\n",
       "      <td>0.2235</td>\n",
       "      <td>18.22</td>\n",
       "      <td>0.6850</td>\n",
       "      <td>23.89</td>\n",
       "      <td>0</td>\n",
       "      <td>6.300422</td>\n",
       "      <td>0.002912</td>\n",
       "      <td>0.110030</td>\n",
       "      <td>0.033847</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>569 rows × 35 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "MeasurementType  area_mean  area_se  area_worst  compactness_mean  \\\n",
       "PatientID                                                           \n",
       "8670                 748.9    48.31      1156.0           0.12230   \n",
       "8913                 515.9    12.68       577.0           0.03729   \n",
       "8915                 687.3    24.87       809.8           0.09823   \n",
       "9047                 507.6    11.36       580.9           0.08836   \n",
       "85715                534.6    24.25       759.4           0.12310   \n",
       "...                    ...      ...         ...               ...   \n",
       "911157302           1384.0    81.89      2022.0           0.11750   \n",
       "911296201            930.9   115.20      1648.0           0.11100   \n",
       "911296202           2501.0   542.20      4254.0           0.19880   \n",
       "911320501            412.7    12.89       495.1           0.05855   \n",
       "911320502            537.3    16.89       687.6           0.05994   \n",
       "\n",
       "MeasurementType  compactness_se  compactness_worst  concave points_mean  \\\n",
       "PatientID                                                                 \n",
       "8670                    0.01484             0.2394              0.08087   \n",
       "8913                    0.01345             0.1147              0.01171   \n",
       "8915                    0.02115             0.3030              0.04819   \n",
       "9047                    0.01285             0.1958              0.02390   \n",
       "85715                   0.02336             0.4166              0.07340   \n",
       "...                         ...                ...                  ...   \n",
       "911157302               0.02075             0.3101              0.11550   \n",
       "911296201               0.02219             0.2444              0.06431   \n",
       "911296202               0.05374             0.4256              0.16890   \n",
       "911320501               0.01701             0.1808              0.01777   \n",
       "911320502               0.01493             0.1965              0.02870   \n",
       "\n",
       "MeasurementType  concave points_se  concave points_worst  concavity_mean  ...  \\\n",
       "PatientID                                                                 ...   \n",
       "8670                      0.010930               0.15140         0.14660  ...   \n",
       "8913                      0.005905               0.05366         0.02260  ...   \n",
       "8915                      0.011870               0.14890         0.05940  ...   \n",
       "9047                      0.007308               0.08388         0.03296  ...   \n",
       "85715                     0.012150               0.20880         0.12260  ...   \n",
       "...                            ...                   ...             ...  ...   \n",
       "911157302                 0.014660               0.22800         0.15720  ...   \n",
       "911296201                 0.014580               0.15550         0.10070  ...   \n",
       "911296202                 0.025980               0.26250         0.36350  ...   \n",
       "911320501                 0.007497               0.08288         0.03367  ...   \n",
       "911320502                 0.008463               0.10450         0.04859  ...   \n",
       "\n",
       "MeasurementType  symmetry_se  symmetry_worst  texture_mean  texture_se  \\\n",
       "PatientID                                                                \n",
       "8670                 0.01397          0.2837         19.48      0.7859   \n",
       "8913                 0.01619          0.2309         13.12      0.4690   \n",
       "8915                 0.01522          0.2962         19.10      0.9480   \n",
       "9047                 0.01870          0.3297         16.17      0.9050   \n",
       "85715                0.01743          0.3900         18.66      0.8937   \n",
       "...                      ...             ...           ...         ...   \n",
       "911157302            0.01029          0.2268         20.52      1.3610   \n",
       "911296201            0.02045          0.3010         27.15      1.1520   \n",
       "911296202            0.01697          0.2641         26.27      1.3060   \n",
       "911320501            0.02124          0.3210         18.36      0.7656   \n",
       "911320502            0.01093          0.2235         18.22      0.6850   \n",
       "\n",
       "MeasurementType  texture_worst  Diagnosis  Area_Perimeter_Ratio  \\\n",
       "PatientID                                                         \n",
       "8670                     26.00          1              7.292113   \n",
       "8913                     15.54          0              6.223911   \n",
       "8915                     26.19          0              7.011119   \n",
       "9047                     23.02          0              6.029936   \n",
       "85715                    27.95          1              6.146241   \n",
       "...                        ...        ...                   ...   \n",
       "911157302                32.07          1              9.949676   \n",
       "911296201                34.49          1              8.296791   \n",
       "911296202                31.37          1             13.310271   \n",
       "911320501                24.02          0              5.511485   \n",
       "911320502                23.89          0              6.300422   \n",
       "\n",
       "MeasurementType  Concavity_Compactness_Product  Smoothness_Symmetry_Avg  \\\n",
       "PatientID                                                                 \n",
       "8670                                  0.017929                 0.151150   \n",
       "8913                                  0.000843                 0.101625   \n",
       "8915                                  0.005835                 0.138910   \n",
       "9047                                  0.002912                 0.136145   \n",
       "85715                                 0.015092                 0.164300   \n",
       "...                                        ...                      ...   \n",
       "911157302                             0.018471                 0.126120   \n",
       "911296201                             0.011178                 0.139140   \n",
       "911296202                             0.072264                 0.157250   \n",
       "911320501                             0.001971                 0.118340   \n",
       "911320502                             0.002912                 0.110030   \n",
       "\n",
       "MeasurementType  Texture_Area_Ratio  \n",
       "PatientID                            \n",
       "8670                       0.025977  \n",
       "8913                       0.025382  \n",
       "8915                       0.027750  \n",
       "9047                       0.031793  \n",
       "85715                      0.034839  \n",
       "...                             ...  \n",
       "911157302                  0.014816  \n",
       "911296201                  0.029134  \n",
       "911296202                  0.010500  \n",
       "911320501                  0.044380  \n",
       "911320502                  0.033847  \n",
       "\n",
       "[569 rows x 35 columns]"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_pivoted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "ff634b84-5dfa-4319-8fd4-8874b506f74e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train/Test Split\n",
    "X = data_pivoted.drop(columns=['Diagnosis'])\n",
    "y = data_pivoted['Diagnosis']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, stratify=y, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8dada63-5d77-4035-968c-4220864e5019",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import dagshub\n",
    "dagshub.init(repo_owner='rajasaikatukuri', repo_name='pythonproject', mlflow=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "5d946466-3443-4e96-bbee-faa68dc9617d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create preprocessing pipeline\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', Pipeline([\n",
    "            ('scaler', StandardScaler()),\n",
    "            ('minmax', MinMaxScaler()),\n",
    "            ('log', FunctionTransformer(np.log1p))\n",
    "        ]), X_train.columns)\n",
    "    ]\n",
    ")\n",
    "# Combine preprocessing with Logistic Regression\n",
    "pipeline = Pipeline([\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('classifier', LogisticRegression(random_state=42))\n",
    "])\n",
    "\n",
    "# Hyperparameter tuning\n",
    "param_grid = {\n",
    "    'classifier__C': [0.1, 1.0, 10.0],\n",
    "    'classifier__penalty': ['l2'],\n",
    "    'classifier__solver': ['lbfgs', 'liblinear']\n",
    "}\n",
    "\n",
    "cv = GridSearchCV(pipeline, param_grid, cv=3, scoring='f1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "6f0fad4a-cc8f-4847-b851-cd5990fe1bc7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Experiment: artifact_location='mlflow-artifacts:/1ccacf0c452e41938cec1abeeadfdca2', creation_time=1734635027621, experiment_id='0', last_update_time=1734635027621, lifecycle_stage='active', name='Breast Cancer Logistic Regression Experiment', tags={}>"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# MLFlow logging setup\n",
    "mlflow.set_tracking_uri(\"https://dagshub.com/rajasaikatukuri/pythonproject.mlflow\")\n",
    "mlflow.set_experiment(\"Breast Cancer Logistic Regression Experiment 1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "647a2067-c8fe-452f-85ef-5654ad4e59da",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[31m2024/12/19 15:29:29 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🏃 View run auspicious-snake-45 at: https://dagshub.com/rajasaikatukuri/pythonproject.mlflow/#/experiments/0/runs/f3b64d8640a84ce883195dc939071c1f\n",
      "🧪 View experiment at: https://dagshub.com/rajasaikatukuri/pythonproject.mlflow/#/experiments/0\n",
      "MLFlow Run Completed\n"
     ]
    }
   ],
   "source": [
    "with mlflow.start_run():\n",
    "    # Cross-validation\n",
    "    cv.fit(X_train, y_train)\n",
    "\n",
    "    # Log model parameters and metrics\n",
    "    mlflow.log_param(\"Best Params\", cv.best_params_)\n",
    "\n",
    "    mean_cv_f1 = cv.best_score_\n",
    "    mlflow.log_metric(\"Mean CV F1\", mean_cv_f1)\n",
    "\n",
    "    # Evaluate on test data\n",
    "    y_pred = cv.best_estimator_.predict(X_test)\n",
    "    test_f1 = f1_score(y_test, y_pred)\n",
    "    mlflow.log_metric(\"Test F1\", test_f1)\n",
    "\n",
    "    tn, fp, fn, tp = confusion_matrix(y_test, y_pred).ravel()\n",
    "    mlflow.log_metric(\"True Positives\", tp)\n",
    "    mlflow.log_metric(\"True Negatives\", tn)\n",
    "    mlflow.log_metric(\"False Positives\", fp)\n",
    "    mlflow.log_metric(\"False Negatives\", fn)\n",
    "\n",
    "    # Log the model\n",
    "    mlflow.sklearn.log_model(cv.best_estimator_, \"model\")\n",
    "\n",
    "print(\"MLFlow Run Completed\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35ea68f5-c8a4-451b-9d8c-ddfe7f4e6797",
   "metadata": {},
   "outputs": [],
   "source": [
    "Experiment 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "1661e23e-54c9-4827-89e1-ac7a7cd645b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create preprocessing pipeline\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', Pipeline([\n",
    "            ('scaler', StandardScaler()),\n",
    "            ('minmax', MinMaxScaler()),\n",
    "            ('log', FunctionTransformer(np.log1p))\n",
    "        ]), X_train.columns)\n",
    "    ]\n",
    ")\n",
    "\n",
    "classifiers = {\n",
    "    \"Logistic Regression\": LogisticRegression(random_state=42),\n",
    "    \"Ridge Classifier\": RidgeClassifier(random_state=42),\n",
    "    \"Random Forest\": RandomForestClassifier(random_state=42)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "99f65863-5de8-4e85-bb55-8c8b08b05edf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Experiment: artifact_location='mlflow-artifacts:/7b20c9103dc647d3b06f6b35be44f8f1', creation_time=1734637296736, experiment_id='1', last_update_time=1734637296736, lifecycle_stage='active', name='Breast Cancer Multi-Classifier Experiment', tags={}>"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# MLFlow logging setup\n",
    "mlflow.set_tracking_uri(\"https://dagshub.com/rajasaikatukuri/pythonproject.mlflow\")\n",
    "mlflow.set_experiment(\"Breast Cancer Multi-Classifier Experiment 2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "23c7292a-204e-4623-90f3-5be77f65ec1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/mlflow/types/utils.py:435: UserWarning: Hint: Inferred schema contains integer column(s). Integer columns in Python cannot represent missing values. If your input data contains missing values at inference time, it will be encoded as floats and will cause a schema enforcement error. The best way to avoid this problem is to infer the model schema based on a realistic data sample (training dataset) that includes missing values. Alternatively, you can declare integer columns as doubles (float64) whenever these columns may have missing values. See `Handling Integers With Missing Values <https://www.mlflow.org/docs/latest/models.html#handling-integers-with-missing-values>`_ for more details.\n",
      "  warnings.warn(\n",
      "Registered model 'Logistic_Regression_Pipeline' already exists. Creating a new version of this model...\n",
      "2024/12/19 15:29:52 INFO mlflow.store.model_registry.abstract_store: Waiting up to 300 seconds for model version to finish creation. Model name: Logistic_Regression_Pipeline, version 7\n",
      "Created version '7' of model 'Logistic_Regression_Pipeline'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🏃 View run Logistic Regression at: https://dagshub.com/rajasaikatukuri/pythonproject.mlflow/#/experiments/1/runs/10046bb6df4a4a159c1b7a33599bd896\n",
      "🧪 View experiment at: https://dagshub.com/rajasaikatukuri/pythonproject.mlflow/#/experiments/1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/mlflow/types/utils.py:435: UserWarning: Hint: Inferred schema contains integer column(s). Integer columns in Python cannot represent missing values. If your input data contains missing values at inference time, it will be encoded as floats and will cause a schema enforcement error. The best way to avoid this problem is to infer the model schema based on a realistic data sample (training dataset) that includes missing values. Alternatively, you can declare integer columns as doubles (float64) whenever these columns may have missing values. See `Handling Integers With Missing Values <https://www.mlflow.org/docs/latest/models.html#handling-integers-with-missing-values>`_ for more details.\n",
      "  warnings.warn(\n",
      "Registered model 'Ridge_Classifier_Pipeline' already exists. Creating a new version of this model...\n",
      "2024/12/19 15:30:14 INFO mlflow.store.model_registry.abstract_store: Waiting up to 300 seconds for model version to finish creation. Model name: Ridge_Classifier_Pipeline, version 7\n",
      "Created version '7' of model 'Ridge_Classifier_Pipeline'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🏃 View run Ridge Classifier at: https://dagshub.com/rajasaikatukuri/pythonproject.mlflow/#/experiments/1/runs/9bb33eeb07414493acf3d3a88c5f466f\n",
      "🧪 View experiment at: https://dagshub.com/rajasaikatukuri/pythonproject.mlflow/#/experiments/1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/mlflow/types/utils.py:435: UserWarning: Hint: Inferred schema contains integer column(s). Integer columns in Python cannot represent missing values. If your input data contains missing values at inference time, it will be encoded as floats and will cause a schema enforcement error. The best way to avoid this problem is to infer the model schema based on a realistic data sample (training dataset) that includes missing values. Alternatively, you can declare integer columns as doubles (float64) whenever these columns may have missing values. See `Handling Integers With Missing Values <https://www.mlflow.org/docs/latest/models.html#handling-integers-with-missing-values>`_ for more details.\n",
      "  warnings.warn(\n",
      "Registered model 'Random_Forest_Pipeline' already exists. Creating a new version of this model...\n",
      "2024/12/19 15:30:36 INFO mlflow.store.model_registry.abstract_store: Waiting up to 300 seconds for model version to finish creation. Model name: Random_Forest_Pipeline, version 7\n",
      "Created version '7' of model 'Random_Forest_Pipeline'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🏃 View run Random Forest at: https://dagshub.com/rajasaikatukuri/pythonproject.mlflow/#/experiments/1/runs/6420746b22054ca9bc80f344f313d744\n",
      "🧪 View experiment at: https://dagshub.com/rajasaikatukuri/pythonproject.mlflow/#/experiments/1\n"
     ]
    }
   ],
   "source": [
    "for name, clf in classifiers.items():\n",
    "    with mlflow.start_run(run_name=name):\n",
    "        pipeline = Pipeline([\n",
    "            ('preprocessor', preprocessor),\n",
    "            ('classifier', clf)\n",
    "        ])\n",
    "\n",
    "        # Cross-validation\n",
    "        cv_scores = cross_val_score(pipeline, X_train, y_train, cv=3, scoring='f1')\n",
    "        mean_cv_f1 = np.mean(cv_scores)\n",
    "        std_cv_f1 = np.std(cv_scores)\n",
    "        mlflow.log_metric(\"Mean_CV_F1\", mean_cv_f1)\n",
    "        mlflow.log_metric(\"Std_CV_F1\", std_cv_f1)\n",
    "\n",
    "        # Train on full training data\n",
    "        pipeline.fit(X_train, y_train)\n",
    "\n",
    "        # Evaluate on test data\n",
    "        y_pred = pipeline.predict(X_test)\n",
    "        test_f1 = f1_score(y_test, y_pred)\n",
    "        mlflow.log_metric(\"Test_F1\", test_f1)\n",
    "\n",
    "        tn, fp, fn, tp = confusion_matrix(y_test, y_pred).ravel()\n",
    "        mlflow.log_metric(\"True_Positives\", tp)\n",
    "        mlflow.log_metric(\"True_Negatives\", tn)\n",
    "        mlflow.log_metric(\"False_Positives\", fp)\n",
    "        mlflow.log_metric(\"False_Negatives\", fn)\n",
    "\n",
    "        # Log the model\n",
    "        mlflow.sklearn.log_model(\n",
    "            sk_model=pipeline,\n",
    "            artifact_path=\"model\",\n",
    "            input_example=X_test.iloc[0].to_dict(),\n",
    "            registered_model_name=f\"{name.replace(' ', '_')}_Pipeline\"\n",
    "        )\n",
    "\n",
    "\n",
    "# Create a wrapper for XGBClassifier\n",
    "class SklearnXGBWrapper(BaseEstimator, ClassifierMixin):\n",
    "    def __init__(self, **kwargs):\n",
    "        self.model = XGBClassifier(**kwargs)\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        self.model.fit(X, y)\n",
    "        return self\n",
    "\n",
    "    def predict(self, X):\n",
    "        return self.model.predict(X)\n",
    "\n",
    "    def predict_proba(self, X):\n",
    "        return self.model.predict_proba(X)\n",
    "\n",
    "# Train and evaluate XGBClassifier separately\n",
    "with mlflow.start_run(run_name=\"XGB Classifier\"):\n",
    "    xgb_wrapper = SklearnXGBWrapper(random_state=42, eval_metric='logloss', use_label_encoder=False)\n",
    "\n",
    "    # Cross-validation\n",
    "    cv_scores = cross_val_score(xgb_wrapper, X_train, y_train, cv=3, scoring='f1')\n",
    "    mean_cv_f1 = np.mean(cv_scores)\n",
    "    std_cv_f1 = np.std(cv_scores)\n",
    "    mlflow.log_metric(\"Mean_CV_F1\", mean_cv_f1)\n",
    "    mlflow.log_metric(\"Std_CV_F1\", std_cv_f1)\n",
    "\n",
    "    # Train on full training data\n",
    "    xgb_wrapper.fit(X_train, y_train)\n",
    "\n",
    "    # Evaluate on test data\n",
    "    y_pred = xgb_wrapper.predict(X_test)\n",
    "    test_f1 = f1_score(y_test, y_pred)\n",
    "    mlflow.log_metric(\"Test_F1\", test_f1)\n",
    "\n",
    "    tn, fp, fn, tp = confusion_matrix(y_test, y_pred).ravel()\n",
    "    mlflow.log_metric(\"True_Positives\", tp)\n",
    "    mlflow.log_metric(\"True_Negatives\", tn)\n",
    "    mlflow.log_metric(\"False_Positives\", fp)\n",
    "    mlflow.log_metric(\"False_Negatives\", fn)\n",
    "\n",
    "    # Log the model\n",
    "    mlflow.sklearn.log_model(\n",
    "        sk_model=xgb_wrapper,\n",
    "        artifact_path=\"xgb_model\",\n",
    "        input_example=X_test.iloc[0].to_dict(),\n",
    "        registered_model_name=\"XGB_Classifier\"\n",
    "    )\n",
    "\n",
    "print(\"Experiment #2 Completed\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c64729a-20fc-4cf8-97f7-632e5ffe6963",
   "metadata": {},
   "outputs": [],
   "source": [
    "Experiment 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15324247-a617-4be2-833c-2fe901a15ae9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature Engineering: Attribute Combination\n",
    "# Adding Area_Perimeter_Ratio\n",
    "data_pivoted['Area_Perimeter_Ratio'] = data_pivoted['area_mean'] / (data_pivoted['perimeter_mean'] + 1)\n",
    "\n",
    "# Adding Concavity_Compactness_Product\n",
    "data_pivoted['Concavity_Compactness_Product'] = data_pivoted['concavity_mean'] * data_pivoted['compactness_mean']\n",
    "\n",
    "# Adding Smoothness_Symmetry_Avg\n",
    "data_pivoted['Smoothness_Symmetry_Avg'] = (data_pivoted['smoothness_mean'] + data_pivoted['symmetry_mean']) / 2\n",
    "\n",
    "# Adding Texture_Area_Ratio\n",
    "data_pivoted['Texture_Area_Ratio'] = data_pivoted['texture_mean'] / (data_pivoted['area_mean'] + 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2374585a-b9dc-4d58-bdfb-6486e583cdd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create preprocessing pipeline\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', Pipeline([\n",
    "            ('scaler', StandardScaler()),\n",
    "            ('minmax', MinMaxScaler()),\n",
    "            ('log', FunctionTransformer(np.log1p))\n",
    "        ]), X_train.columns)\n",
    "    ]\n",
    ")\n",
    "\n",
    "classifiers = {\n",
    "    \"Logistic Regression\": LogisticRegression(random_state=42),\n",
    "    \"Ridge Classifier\": RidgeClassifier(random_state=42),\n",
    "    \"Random Forest\": RandomForestClassifier(random_state=42)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17a0b4c1-9ae9-4cf6-aefe-eb5d3c3a7533",
   "metadata": {},
   "outputs": [],
   "source": [
    "# MLFlow logging setup\n",
    "mlflow.set_tracking_uri(\"https://dagshub.com/rajasaikatukuri/pythonproject.mlflow\")\n",
    "mlflow.set_experiment(\"Breast Cancer Multi-Classifier Experiment 2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5f154b8-54af-4ece-8a89-d81af5ba14ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "for name, clf in classifiers.items():\n",
    "    with mlflow.start_run(run_name=name):\n",
    "        pipeline = Pipeline([\n",
    "            ('preprocessor', preprocessor),\n",
    "            ('classifier', clf)\n",
    "        ])\n",
    "\n",
    "        # Cross-validation\n",
    "        cv_scores = cross_val_score(pipeline, X_train, y_train, cv=3, scoring='f1')\n",
    "        mean_cv_f1 = np.mean(cv_scores)\n",
    "        std_cv_f1 = np.std(cv_scores)\n",
    "        mlflow.log_metric(\"Mean_CV_F1\", mean_cv_f1)\n",
    "        mlflow.log_metric(\"Std_CV_F1\", std_cv_f1)\n",
    "\n",
    "        # Train on full training data\n",
    "        pipeline.fit(X_train, y_train)\n",
    "\n",
    "        # Evaluate on test data\n",
    "        y_pred = pipeline.predict(X_test)\n",
    "        test_f1 = f1_score(y_test, y_pred)\n",
    "        mlflow.log_metric(\"Test_F1\", test_f1)\n",
    "\n",
    "        tn, fp, fn, tp = confusion_matrix(y_test, y_pred).ravel()\n",
    "        mlflow.log_metric(\"True_Positives\", tp)\n",
    "        mlflow.log_metric(\"True_Negatives\", tn)\n",
    "        mlflow.log_metric(\"False_Positives\", fp)\n",
    "        mlflow.log_metric(\"False_Negatives\", fn)\n",
    "\n",
    "        # Log the model\n",
    "        mlflow.sklearn.log_model(\n",
    "            sk_model=pipeline,\n",
    "            artifact_path=\"model\",\n",
    "            input_example=X_test.iloc[0].to_dict(),\n",
    "            registered_model_name=f\"{name.replace(' ', '_')}_Pipeline\"\n",
    "        )\n",
    "\n",
    "\n",
    "# Create a wrapper for XGBClassifier\n",
    "class SklearnXGBWrapper(BaseEstimator, ClassifierMixin):\n",
    "    def __init__(self, **kwargs):\n",
    "        self.model = XGBClassifier(**kwargs)\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        self.model.fit(X, y)\n",
    "        return self\n",
    "\n",
    "    def predict(self, X):\n",
    "        return self.model.predict(X)\n",
    "\n",
    "    def predict_proba(self, X):\n",
    "        return self.model.predict_proba(X)\n",
    "\n",
    "# Train and evaluate XGBClassifier separately\n",
    "with mlflow.start_run(run_name=\"XGB Classifier\"):\n",
    "    xgb_wrapper = SklearnXGBWrapper(random_state=42, eval_metric='logloss', use_label_encoder=False)\n",
    "\n",
    "    # Cross-validation\n",
    "    cv_scores = cross_val_score(xgb_wrapper, X_train, y_train, cv=3, scoring='f1')\n",
    "    mean_cv_f1 = np.mean(cv_scores)\n",
    "    std_cv_f1 = np.std(cv_scores)\n",
    "    mlflow.log_metric(\"Mean_CV_F1\", mean_cv_f1)\n",
    "    mlflow.log_metric(\"Std_CV_F1\", std_cv_f1)\n",
    "\n",
    "    # Train on full training data\n",
    "    xgb_wrapper.fit(X_train, y_train)\n",
    "\n",
    "    # Evaluate on test data\n",
    "    y_pred = xgb_wrapper.predict(X_test)\n",
    "    test_f1 = f1_score(y_test, y_pred)\n",
    "    mlflow.log_metric(\"Test_F1\", test_f1)\n",
    "\n",
    "    tn, fp, fn, tp = confusion_matrix(y_test, y_pred).ravel()\n",
    "    mlflow.log_metric(\"True_Positives\", tp)\n",
    "    mlflow.log_metric(\"True_Negatives\", tn)\n",
    "    mlflow.log_metric(\"False_Positives\", fp)\n",
    "    mlflow.log_metric(\"False_Negatives\", fn)\n",
    "\n",
    "    # Log the model\n",
    "    mlflow.sklearn.log_model(\n",
    "        sk_model=xgb_wrapper,\n",
    "        artifact_path=\"xgb_model\",\n",
    "        input_example=X_test.iloc[0].to_dict(),\n",
    "        registered_model_name=\"XGB_Classifier\"\n",
    "    )\n",
    "\n",
    "print(\"Experiment #2 Completed\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "e353590b-adbd-4042-aaeb-3688075b5ce8",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (955269835.py, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[56], line 1\u001b[0;36m\u001b[0m\n\u001b[0;31m    Experiment 4\u001b[0m\n\u001b[0m               ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "***Experiment 4***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "01ddf5c2-9b3c-4cd0-9ac4-4102630e87ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature Selection: Variance Threshold\n",
    "variance_threshold = VarianceThreshold(threshold=0.01)\n",
    "X_train_var = variance_threshold.fit_transform(X_train)\n",
    "X_test_var = variance_threshold.transform(X_test)\n",
    "selected_features_var = X_train.columns[variance_threshold.get_support()]\n",
    "\n",
    "# Feature Selection: Correlation Threshold\n",
    "correlation_matrix = pd.DataFrame(X_train_var, columns=selected_features_var).corr()\n",
    "high_corr_features = [column for column in correlation_matrix.columns if any(correlation_matrix[column].abs() > 0.9) and column != column]\n",
    "remaining_features = [feature for feature in selected_features_var if feature not in high_corr_features]\n",
    "X_train_corr = pd.DataFrame(X_train_var, columns=selected_features_var)[remaining_features]\n",
    "X_test_corr = pd.DataFrame(X_test_var, columns=selected_features_var)[remaining_features]\n",
    "\n",
    "# Feature Selection: SelectKBest (ANOVA F-test)\n",
    "k_best_selector = SelectKBest(score_func=f_classif, k=10)\n",
    "X_train_selected = k_best_selector.fit_transform(X_train_corr, y_train)\n",
    "X_test_selected = k_best_selector.transform(X_test_corr)\n",
    "selected_features_kbest = np.array(remaining_features)[k_best_selector.get_support()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "c44b2524-ab2f-4feb-bda8-44d48f6c0015",
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', Pipeline([\n",
    "            ('scaler', StandardScaler()),\n",
    "            ('minmax', MinMaxScaler()),\n",
    "            ('log', FunctionTransformer(np.log1p))\n",
    "        ]), list(range(X_train_selected.shape[1])))\n",
    "    ]\n",
    ")\n",
    "# Classifiers to evaluate\n",
    "classifiers = {\n",
    "    \"Logistic Regression\": LogisticRegression(random_state=42),\n",
    "    \"Ridge Classifier\": RidgeClassifier(random_state=42),\n",
    "    \"Random Forest\": RandomForestClassifier(random_state=42)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "e295ddfd-3af4-435c-852a-9797f6a162ab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Experiment: artifact_location='mlflow-artifacts:/a2257e8ff4b34999bbe58ce442426951', creation_time=1734640841930, experiment_id='2', last_update_time=1734640841930, lifecycle_stage='active', name='Breast Cancer Multi-Classifier Experiment 4', tags={}>"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# MLFlow logging setup\n",
    "mlflow.set_tracking_uri(\"https://dagshub.com/rajasaikatukuri/pythonproject.mlflow\")\n",
    "mlflow.set_experiment(\"Breast Cancer Multi-Classifier Experiment 4\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "7937e8d9-ec95-45a8-9352-4b0a483147e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/utils/validation.py:2732: UserWarning: X has feature names, but StandardScaler was fitted without feature names\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/mlflow/types/utils.py:435: UserWarning: Hint: Inferred schema contains integer column(s). Integer columns in Python cannot represent missing values. If your input data contains missing values at inference time, it will be encoded as floats and will cause a schema enforcement error. The best way to avoid this problem is to infer the model schema based on a realistic data sample (training dataset) that includes missing values. Alternatively, you can declare integer columns as doubles (float64) whenever these columns may have missing values. See `Handling Integers With Missing Values <https://www.mlflow.org/docs/latest/models.html#handling-integers-with-missing-values>`_ for more details.\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/utils/validation.py:2732: UserWarning: X has feature names, but StandardScaler was fitted without feature names\n",
      "  warnings.warn(\n",
      "Registered model 'Logistic_Regression_Feature_Selection_Pipeline' already exists. Creating a new version of this model...\n",
      "2024/12/19 16:44:23 INFO mlflow.store.model_registry.abstract_store: Waiting up to 300 seconds for model version to finish creation. Model name: Logistic_Regression_Feature_Selection_Pipeline, version 2\n",
      "Created version '2' of model 'Logistic_Regression_Feature_Selection_Pipeline'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🏃 View run Logistic Regression at: https://dagshub.com/rajasaikatukuri/pythonproject.mlflow/#/experiments/2/runs/5a1c53ca05044161a68d85ae6b47d1a1\n",
      "🧪 View experiment at: https://dagshub.com/rajasaikatukuri/pythonproject.mlflow/#/experiments/2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/utils/validation.py:2732: UserWarning: X has feature names, but StandardScaler was fitted without feature names\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/mlflow/types/utils.py:435: UserWarning: Hint: Inferred schema contains integer column(s). Integer columns in Python cannot represent missing values. If your input data contains missing values at inference time, it will be encoded as floats and will cause a schema enforcement error. The best way to avoid this problem is to infer the model schema based on a realistic data sample (training dataset) that includes missing values. Alternatively, you can declare integer columns as doubles (float64) whenever these columns may have missing values. See `Handling Integers With Missing Values <https://www.mlflow.org/docs/latest/models.html#handling-integers-with-missing-values>`_ for more details.\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/utils/validation.py:2732: UserWarning: X has feature names, but StandardScaler was fitted without feature names\n",
      "  warnings.warn(\n",
      "Registered model 'Ridge_Classifier_Feature_Selection_Pipeline' already exists. Creating a new version of this model...\n",
      "2024/12/19 16:44:45 INFO mlflow.store.model_registry.abstract_store: Waiting up to 300 seconds for model version to finish creation. Model name: Ridge_Classifier_Feature_Selection_Pipeline, version 2\n",
      "Created version '2' of model 'Ridge_Classifier_Feature_Selection_Pipeline'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🏃 View run Ridge Classifier at: https://dagshub.com/rajasaikatukuri/pythonproject.mlflow/#/experiments/2/runs/0d3b082b6b2f410589e1cf84438a65a2\n",
      "🧪 View experiment at: https://dagshub.com/rajasaikatukuri/pythonproject.mlflow/#/experiments/2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/utils/validation.py:2732: UserWarning: X has feature names, but StandardScaler was fitted without feature names\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/mlflow/types/utils.py:435: UserWarning: Hint: Inferred schema contains integer column(s). Integer columns in Python cannot represent missing values. If your input data contains missing values at inference time, it will be encoded as floats and will cause a schema enforcement error. The best way to avoid this problem is to infer the model schema based on a realistic data sample (training dataset) that includes missing values. Alternatively, you can declare integer columns as doubles (float64) whenever these columns may have missing values. See `Handling Integers With Missing Values <https://www.mlflow.org/docs/latest/models.html#handling-integers-with-missing-values>`_ for more details.\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/utils/validation.py:2732: UserWarning: X has feature names, but StandardScaler was fitted without feature names\n",
      "  warnings.warn(\n",
      "Registered model 'Random_Forest_Feature_Selection_Pipeline' already exists. Creating a new version of this model...\n",
      "2024/12/19 16:45:07 INFO mlflow.store.model_registry.abstract_store: Waiting up to 300 seconds for model version to finish creation. Model name: Random_Forest_Feature_Selection_Pipeline, version 2\n",
      "Created version '2' of model 'Random_Forest_Feature_Selection_Pipeline'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🏃 View run Random Forest at: https://dagshub.com/rajasaikatukuri/pythonproject.mlflow/#/experiments/2/runs/aa22bc31c319457ab4de9022b30ab676\n",
      "🧪 View experiment at: https://dagshub.com/rajasaikatukuri/pythonproject.mlflow/#/experiments/2\n"
     ]
    }
   ],
   "source": [
    "for name, clf in classifiers.items():\n",
    "    with mlflow.start_run(run_name=name):\n",
    "        pipeline = Pipeline([\n",
    "            ('preprocessor', preprocessor),\n",
    "            ('classifier', clf)\n",
    "        ])\n",
    "\n",
    "        # Cross-validation\n",
    "        cv_scores = cross_val_score(pipeline, X_train_selected, y_train, cv=3, scoring='f1')\n",
    "        mean_cv_f1 = np.mean(cv_scores)\n",
    "        std_cv_f1 = np.std(cv_scores)\n",
    "        mlflow.log_metric(\"Mean_CV_F1\", mean_cv_f1)\n",
    "        mlflow.log_metric(\"Std_CV_F1\", std_cv_f1)\n",
    "\n",
    "        # Train on full training data\n",
    "        pipeline.fit(X_train_selected, y_train)\n",
    "\n",
    "        # Evaluate on test data\n",
    "        y_pred = pipeline.predict(X_test_selected)\n",
    "        test_f1 = f1_score(y_test, y_pred)\n",
    "        mlflow.log_metric(\"Test_F1\", test_f1)\n",
    "\n",
    "        tn, fp, fn, tp = confusion_matrix(y_test, y_pred).ravel()\n",
    "        mlflow.log_metric(\"True_Positives\", tp)\n",
    "        mlflow.log_metric(\"True_Negatives\", tn)\n",
    "        mlflow.log_metric(\"False_Positives\", fp)\n",
    "        mlflow.log_metric(\"False_Negatives\", fn)\n",
    "\n",
    "        # Log the model\n",
    "        mlflow.sklearn.log_model(\n",
    "            sk_model=pipeline,\n",
    "            artifact_path=\"model\",\n",
    "            input_example=pd.DataFrame(X_test_selected, columns=selected_features_kbest).iloc[:1],\n",
    "            registered_model_name=f\"{name.replace(' ', '_')}_Feature_Selection_Pipeline\"\n",
    "        )\n",
    "class SklearnXGBWrapper(BaseEstimator, ClassifierMixin):\n",
    "    def __init__(self, **kwargs):\n",
    "        self.model = XGBClassifier(**kwargs)\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        self.model.fit(X, y)\n",
    "        return self\n",
    "\n",
    "    def predict(self, X):\n",
    "        return self.model.predict(X)\n",
    "\n",
    "    def predict_proba(self, X):\n",
    "        return self.model.predict_proba(X)\n",
    "\n",
    "# Train and evaluate XGBClassifier separately\n",
    "with mlflow.start_run(run_name=\"XGB Classifier\"):\n",
    "    xgb_wrapper = SklearnXGBWrapper(random_state=42, eval_metric='logloss', use_label_encoder=False)\n",
    "\n",
    "    # Cross-validation\n",
    "    cv_scores = cross_val_score(xgb_wrapper, X_train_selected, y_train, cv=3, scoring='f1')\n",
    "    mean_cv_f1 = np.mean(cv_scores)\n",
    "    std_cv_f1 = np.std(cv_scores)\n",
    "    mlflow.log_metric(\"Mean_CV_F1\", mean_cv_f1)\n",
    "    mlflow.log_metric(\"Std_CV_F1\", std_cv_f1)\n",
    "\n",
    "    # Train on full training data\n",
    "    xgb_wrapper.fit(X_train_selected, y_train)\n",
    "\n",
    "    # Evaluate on test data\n",
    "    y_pred = xgb_wrapper.predict(X_test_selected)\n",
    "    test_f1 = f1_score(y_test, y_pred)\n",
    "    mlflow.log_metric(\"Test_F1\", test_f1)\n",
    "\n",
    "    tn, fp, fn, tp = confusion_matrix(y_test, y_pred).ravel()\n",
    "    mlflow.log_metric(\"True_Positives\", tp)\n",
    "    mlflow.log_metric(\"True_Negatives\", tn)\n",
    "    mlflow.log_metric(\"False_Positives\", fp)\n",
    "    mlflow.log_metric(\"False_Negatives\", fn)\n",
    "\n",
    "    # Log the model\n",
    "    mlflow.sklearn.log_model(\n",
    "        sk_model=xgb_wrapper,\n",
    "        artifact_path=\"xgb_model\",\n",
    "        input_example=pd.DataFrame(X_test_selected, columns=selected_features_kbest).iloc[0].to_dict(),\n",
    "        registered_model_name=\"XGB_Classifier\"\n",
    "    )\n",
    "\n",
    "print(\"Experiment #4 with Feature Selection and XGB Classifier Completed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "bb1de954-475a-497d-ba6f-6b5246254d89",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [16:35:55] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/mlflow/types/utils.py:435: UserWarning: Hint: Inferred schema contains integer column(s). Integer columns in Python cannot represent missing values. If your input data contains missing values at inference time, it will be encoded as floats and will cause a schema enforcement error. The best way to avoid this problem is to infer the model schema based on a realistic data sample (training dataset) that includes missing values. Alternatively, you can declare integer columns as doubles (float64) whenever these columns may have missing values. See `Handling Integers With Missing Values <https://www.mlflow.org/docs/latest/models.html#handling-integers-with-missing-values>`_ for more details.\n",
      "  warnings.warn(\n",
      "Registered model 'XGB_Classifier' already exists. Creating a new version of this model...\n",
      "2024/12/19 16:36:03 INFO mlflow.store.model_registry.abstract_store: Waiting up to 300 seconds for model version to finish creation. Model name: XGB_Classifier, version 5\n",
      "Created version '5' of model 'XGB_Classifier'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🏃 View run XGB Classifier at: https://dagshub.com/rajasaikatukuri/pythonproject.mlflow/#/experiments/2/runs/14df720b7ac84efcba54e9a07110bdc0\n",
      "🧪 View experiment at: https://dagshub.com/rajasaikatukuri/pythonproject.mlflow/#/experiments/2\n",
      "Experiment #4 with Feature Selection and XGB Classifier Completed\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "753e751e-4109-482d-90a3-3fbc114982d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "Experiment 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "9a9f93b3-dba8-4728-8335-ced5fef5ffb2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected number of components: 1\n"
     ]
    }
   ],
   "source": [
    "# Dimensionality Reduction with PCA\n",
    "pca = PCA()\n",
    "X_train_pca = pca.fit_transform(X_train)\n",
    "X_test_pca = pca.transform(X_test)\n",
    "\n",
    "# Scree Plot\n",
    "explained_variance_ratio = pca.explained_variance_ratio_\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(range(1, len(explained_variance_ratio) + 1), explained_variance_ratio, marker='o', linestyle='--')\n",
    "plt.title('Scree Plot')\n",
    "plt.xlabel('Principal Component')\n",
    "plt.ylabel('Variance Explained')\n",
    "plt.show()\n",
    "\n",
    "# Selecting Top Components\n",
    "cumulative_variance = np.cumsum(explained_variance_ratio)\n",
    "selected_components = np.argmax(cumulative_variance >= 0.95) + 1\n",
    "print(f\"Selected number of components: {selected_components}\")\n",
    "\n",
    "X_train_pca_selected = X_train_pca[:, :selected_components]\n",
    "X_test_pca_selected = X_test_pca[:, :selected_components]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "86d9b317-84bb-475b-b6da-de13abfb915c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocessor with StandardScaler, MinMaxScaler, and Log Transformation\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', Pipeline([\n",
    "            ('scaler', StandardScaler()),\n",
    "            ('minmax', MinMaxScaler()),\n",
    "            ('log', FunctionTransformer(np.log1p))\n",
    "        ]), list(range(X_train.shape[1])))\n",
    "    ]\n",
    ")\n",
    "classifiers = {\n",
    "    \"Logistic Regression\": LogisticRegression(random_state=42),\n",
    "    \"Ridge Classifier\": RidgeClassifier(random_state=42),\n",
    "    \"Random Forest\": RandomForestClassifier(random_state=42)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "250eea31-4220-48f5-85a2-39ecd597037a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/12/19 16:51:02 INFO mlflow.tracking.fluent: Experiment with name 'Breast Cancer Multi-Classifier Experiment 5' does not exist. Creating a new experiment.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Experiment: artifact_location='mlflow-artifacts:/edcb42e9397b4e14b9c33fadbca3da04', creation_time=1734645062784, experiment_id='3', last_update_time=1734645062784, lifecycle_stage='active', name='Breast Cancer Multi-Classifier Experiment 5', tags={}>"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# MLFlow logging setup\n",
    "mlflow.set_tracking_uri(\"https://dagshub.com/rajasaikatukuri/pythonproject.mlflow\")\n",
    "mlflow.set_experiment(\"Breast Cancer Multi-Classifier Experiment 5\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "82d2c784-591a-4d27-a098-ab56a47de0ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/mlflow/types/utils.py:435: UserWarning: Hint: Inferred schema contains integer column(s). Integer columns in Python cannot represent missing values. If your input data contains missing values at inference time, it will be encoded as floats and will cause a schema enforcement error. The best way to avoid this problem is to infer the model schema based on a realistic data sample (training dataset) that includes missing values. Alternatively, you can declare integer columns as doubles (float64) whenever these columns may have missing values. See `Handling Integers With Missing Values <https://www.mlflow.org/docs/latest/models.html#handling-integers-with-missing-values>`_ for more details.\n",
      "  warnings.warn(\n",
      "Registered model 'Logistic_Regression_PCA_Pipeline' already exists. Creating a new version of this model...\n",
      "2024/12/19 17:02:25 INFO mlflow.store.model_registry.abstract_store: Waiting up to 300 seconds for model version to finish creation. Model name: Logistic_Regression_PCA_Pipeline, version 2\n",
      "Created version '2' of model 'Logistic_Regression_PCA_Pipeline'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🏃 View run Logistic Regression with PCA at: https://dagshub.com/rajasaikatukuri/pythonproject.mlflow/#/experiments/3/runs/dce73aca4afe47669aae9538c90b2ef9\n",
      "🧪 View experiment at: https://dagshub.com/rajasaikatukuri/pythonproject.mlflow/#/experiments/3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/mlflow/types/utils.py:435: UserWarning: Hint: Inferred schema contains integer column(s). Integer columns in Python cannot represent missing values. If your input data contains missing values at inference time, it will be encoded as floats and will cause a schema enforcement error. The best way to avoid this problem is to infer the model schema based on a realistic data sample (training dataset) that includes missing values. Alternatively, you can declare integer columns as doubles (float64) whenever these columns may have missing values. See `Handling Integers With Missing Values <https://www.mlflow.org/docs/latest/models.html#handling-integers-with-missing-values>`_ for more details.\n",
      "  warnings.warn(\n",
      "Registered model 'Ridge_Classifier_PCA_Pipeline' already exists. Creating a new version of this model...\n",
      "2024/12/19 17:02:47 INFO mlflow.store.model_registry.abstract_store: Waiting up to 300 seconds for model version to finish creation. Model name: Ridge_Classifier_PCA_Pipeline, version 2\n",
      "Created version '2' of model 'Ridge_Classifier_PCA_Pipeline'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🏃 View run Ridge Classifier with PCA at: https://dagshub.com/rajasaikatukuri/pythonproject.mlflow/#/experiments/3/runs/bbd279e914554528ae3cc96bf488d98f\n",
      "🧪 View experiment at: https://dagshub.com/rajasaikatukuri/pythonproject.mlflow/#/experiments/3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/mlflow/types/utils.py:435: UserWarning: Hint: Inferred schema contains integer column(s). Integer columns in Python cannot represent missing values. If your input data contains missing values at inference time, it will be encoded as floats and will cause a schema enforcement error. The best way to avoid this problem is to infer the model schema based on a realistic data sample (training dataset) that includes missing values. Alternatively, you can declare integer columns as doubles (float64) whenever these columns may have missing values. See `Handling Integers With Missing Values <https://www.mlflow.org/docs/latest/models.html#handling-integers-with-missing-values>`_ for more details.\n",
      "  warnings.warn(\n",
      "Registered model 'Random_Forest_PCA_Pipeline' already exists. Creating a new version of this model...\n",
      "2024/12/19 17:03:09 INFO mlflow.store.model_registry.abstract_store: Waiting up to 300 seconds for model version to finish creation. Model name: Random_Forest_PCA_Pipeline, version 2\n",
      "Created version '2' of model 'Random_Forest_PCA_Pipeline'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🏃 View run Random Forest with PCA at: https://dagshub.com/rajasaikatukuri/pythonproject.mlflow/#/experiments/3/runs/b7541ae0b7a541969302be5f2c293981\n",
      "🧪 View experiment at: https://dagshub.com/rajasaikatukuri/pythonproject.mlflow/#/experiments/3\n"
     ]
    }
   ],
   "source": [
    "for name, clf in classifiers.items():\n",
    "    with mlflow.start_run(run_name=f\"{name} with PCA\"):\n",
    "        pipeline = Pipeline([\n",
    "            ('preprocessor', preprocessor),\n",
    "            ('pca', PCA(n_components=selected_components)),\n",
    "            ('classifier', clf)\n",
    "        ])\n",
    "\n",
    "        # Cross-validation\n",
    "        cv_scores = cross_val_score(pipeline, X_train, y_train, cv=3, scoring='f1')\n",
    "        mean_cv_f1 = np.mean(cv_scores)\n",
    "        std_cv_f1 = np.std(cv_scores)\n",
    "        mlflow.log_metric(\"Mean_CV_F1\", mean_cv_f1)\n",
    "        mlflow.log_metric(\"Std_CV_F1\", std_cv_f1)\n",
    "\n",
    "        # Train on full training data\n",
    "        pipeline.fit(X_train, y_train)\n",
    "\n",
    "        # Evaluate on test data\n",
    "        y_pred = pipeline.predict(X_test)\n",
    "        test_f1 = f1_score(y_test, y_pred)\n",
    "        mlflow.log_metric(\"Test_F1\", test_f1)\n",
    "\n",
    "        tn, fp, fn, tp = confusion_matrix(y_test, y_pred).ravel()\n",
    "        mlflow.log_metric(\"True_Positives\", tp)\n",
    "        mlflow.log_metric(\"True_Negatives\", tn)\n",
    "        mlflow.log_metric(\"False_Positives\", fp)\n",
    "        mlflow.log_metric(\"False_Negatives\", fn)\n",
    "\n",
    "        # Log the model\n",
    "        mlflow.sklearn.log_model(\n",
    "            sk_model=pipeline,\n",
    "            artifact_path=\"model\",\n",
    "            input_example=pd.DataFrame(X_test).iloc[:1],\n",
    "            registered_model_name=f\"{name.replace(' ', '_')}_PCA_Pipeline\"\n",
    "        )\n",
    "# Updated MLFlow for XGBClassifier with Preprocessor\n",
    "class SklearnXGBWrapper(BaseEstimator, ClassifierMixin):\n",
    "    def __init__(self, **kwargs):\n",
    "        self.model = XGBClassifier(**kwargs)\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        self.model.fit(X, y)\n",
    "        return self\n",
    "\n",
    "    def predict(self, X):\n",
    "        return self.model.predict(X)\n",
    "\n",
    "    def predict_proba(self, X):\n",
    "        return self.model.predict_proba(X)\n",
    "\n",
    "# Train and evaluate XGBClassifier with integrated preprocessor\n",
    "with mlflow.start_run(run_name=\"XGB Classifier with Preprocessor and PCA\"):\n",
    "    xgb_wrapper = SklearnXGBWrapper(random_state=42, eval_metric='logloss', use_label_encoder=False)\n",
    "\n",
    "    # Create pipeline with preprocessor\n",
    "    pipeline = Pipeline([\n",
    "        ('preprocessor', preprocessor),\n",
    "        ('pca', PCA(n_components=selected_components)),  # Apply PCA after preprocessing\n",
    "        ('classifier', xgb_wrapper)\n",
    "    ])\n",
    "\n",
    "    # Cross-validation\n",
    "    cv_scores = cross_val_score(pipeline, X_train, y_train, cv=3, scoring='f1')\n",
    "    mean_cv_f1 = np.mean(cv_scores)\n",
    "    std_cv_f1 = np.std(cv_scores)\n",
    "    mlflow.log_metric(\"Mean_CV_F1\", mean_cv_f1)\n",
    "    mlflow.log_metric(\"Std_CV_F1\", std_cv_f1)\n",
    "\n",
    "    # Train on full training data\n",
    "    pipeline.fit(X_train, y_train)\n",
    "\n",
    "    # Evaluate on test data\n",
    "    y_pred = pipeline.predict(X_test)\n",
    "    test_f1 = f1_score(y_test, y_pred)\n",
    "    mlflow.log_metric(\"Test_F1\", test_f1)\n",
    "\n",
    "    tn, fp, fn, tp = confusion_matrix(y_test, y_pred).ravel()\n",
    "    mlflow.log_metric(\"True_Positives\", tp)\n",
    "    mlflow.log_metric(\"True_Negatives\", tn)\n",
    "    mlflow.log_metric(\"False_Positives\", fp)\n",
    "    mlflow.log_metric(\"False_Negatives\", fn)\n",
    "\n",
    "    # Log the model\n",
    "    mlflow.sklearn.log_model(\n",
    "        sk_model=pipeline,\n",
    "        artifact_path=\"xgb_model_with_preprocessor\",\n",
    "        input_example=pd.DataFrame(X_test).iloc[:1],\n",
    "        registered_model_name=\"XGB_Classifier_with_Preprocessor_and_PCA\"\n",
    "    )\n",
    "\n",
    "print(\"Experiment with XGBClassifier, Preprocessor, and PCA Completed\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "3b3defd7-27c7-449e-a070-7d4884c25b5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/pipeline.py:62: FutureWarning: This Pipeline instance is not fitted yet. Call 'fit' with appropriate arguments before using other methods such as transform, predict, etc. This will raise an error in 1.8 instead of the current warning.\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/pipeline.py:62: FutureWarning: This Pipeline instance is not fitted yet. Call 'fit' with appropriate arguments before using other methods such as transform, predict, etc. This will raise an error in 1.8 instead of the current warning.\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/pipeline.py:62: FutureWarning: This Pipeline instance is not fitted yet. Call 'fit' with appropriate arguments before using other methods such as transform, predict, etc. This will raise an error in 1.8 instead of the current warning.\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [17:03:14] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/pipeline.py:62: FutureWarning: This Pipeline instance is not fitted yet. Call 'fit' with appropriate arguments before using other methods such as transform, predict, etc. This will raise an error in 1.8 instead of the current warning.\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/pipeline.py:62: FutureWarning: This Pipeline instance is not fitted yet. Call 'fit' with appropriate arguments before using other methods such as transform, predict, etc. This will raise an error in 1.8 instead of the current warning.\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/mlflow/types/utils.py:435: UserWarning: Hint: Inferred schema contains integer column(s). Integer columns in Python cannot represent missing values. If your input data contains missing values at inference time, it will be encoded as floats and will cause a schema enforcement error. The best way to avoid this problem is to infer the model schema based on a realistic data sample (training dataset) that includes missing values. Alternatively, you can declare integer columns as doubles (float64) whenever these columns may have missing values. See `Handling Integers With Missing Values <https://www.mlflow.org/docs/latest/models.html#handling-integers-with-missing-values>`_ for more details.\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/pipeline.py:62: FutureWarning: This Pipeline instance is not fitted yet. Call 'fit' with appropriate arguments before using other methods such as transform, predict, etc. This will raise an error in 1.8 instead of the current warning.\n",
      "  warnings.warn(\n",
      "Successfully registered model 'XGB_Classifier_with_Preprocessor_and_PCA'.\n",
      "2024/12/19 17:03:31 INFO mlflow.store.model_registry.abstract_store: Waiting up to 300 seconds for model version to finish creation. Model name: XGB_Classifier_with_Preprocessor_and_PCA, version 1\n",
      "Created version '1' of model 'XGB_Classifier_with_Preprocessor_and_PCA'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🏃 View run XGB Classifier with Preprocessor and PCA at: https://dagshub.com/rajasaikatukuri/pythonproject.mlflow/#/experiments/3/runs/e6f980eaacb44843a4b084e4b17601b5\n",
      "🧪 View experiment at: https://dagshub.com/rajasaikatukuri/pythonproject.mlflow/#/experiments/3\n",
      "Experiment with XGBClassifier, Preprocessor, and PCA Completed\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3169f1cb-7698-4377-9445-fa876b41effb",
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e5b9379-ad7c-4149-ab17-0b42074a6aa1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
